---
title: "testing_model_pred"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
little_features <- calculate_features(little_test$seq.aa)
```


```{r}

library(caret)

load("svmRadialwithprobamph.Rdata")


#using the second model to predict probabilities and class (bg or tg)
class_little_features <- predict(svmRadialwithprob_amph, little_features)
class_little_features <- as.data.frame(class_little_features)

prob_little_features <- predict(svmRadialwithprob_amph, little_features, type = "prob")

#bit concerning here, depending on the run of the model, there is a ~.2 difference in probability values (e.g same protein predicted with 0.75 vs 0.95 or 0.35 vs 0.55)

predict(svmRadialwithprob_amph, little_features, type = "prob")

```


```{r}
names(prob_little_features)[2] <- "prob_AMP"

names(prob_little_features)[names(prob_little_features) == "Tg"] <- "prob_AMP"
```


```{r}
predict_AMP_prob <- function(df) {
  #load model
  load("svmRadialwithprobamph.Rdata")

  p_AMP <- predict(svmRadialwithprob_amph, df, type = "prob")
  
  names(p_AMP)[names(p_AMP) == "Tg"] <- "prob_AMP"
  
  #only show the TG/prob_AMP column
  #maybe 1 column as class, second column probability? 
  
  #as.data.frame(p_AMP$prob_AMP)

}


predict_AMP_prob(little_features)
```

